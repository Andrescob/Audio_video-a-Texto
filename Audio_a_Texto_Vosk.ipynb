{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCrJgrycluBqy7hRBZ/vzH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d4d522f3153b47d39d721d852f8b8d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 0,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".mp4,.wav",
            "button_style": "",
            "data": [],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_0df3b3bc3959406ab806d4999959f5a1",
            "metadata": [],
            "multiple": false,
            "style": "IPY_MODEL_8e4b9b8c70214739ac3068cf6cf1672f"
          }
        },
        "0df3b3bc3959406ab806d4999959f5a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e4b9b8c70214739ac3068cf6cf1672f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrescob/Audio_video-a-Texto/blob/main/Audio_a_Texto_Vosk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "!pip install vosk\n",
        "import subprocess  # For ffmpeg\n",
        "import vosk\n",
        "import os\n",
        "\n",
        "# 0. Download the model if it doesn't exist\n",
        "model_name = \"vosk-model-en-us-0.22\"\n",
        "model_dir = model_name\n",
        "if not os.path.exists(model_dir):\n",
        "    print(f\"Downloading model '{model_name}'...\")\n",
        "    !wget https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip\n",
        "    !unzip vosk-model-en-us-0.22.zip\n",
        "    print(\"Model downloaded and extracted.\")\n",
        "else:\n",
        "    print(f\"Model '{model_name}' already exists.\")\n",
        "\n",
        "# 1. Audio Extraction (using ffmpeg)\n",
        "try:\n",
        "    # Check if input.mp4 exists\n",
        "    if not os.path.exists('input.mp4'):\n",
        "        raise FileNotFoundError(\"Error: input.mp4 not found in the current directory.\")\n",
        "\n",
        "    subprocess.run(['ffmpeg', '-i', 'input.mp4', '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', 'audio.wav'], check=True, capture_output=True)\n",
        "\n",
        "    # Check if audio.wav exists after ffmpeg\n",
        "    if not os.path.exists('audio.wav'):\n",
        "          raise FileNotFoundError(\"Error: audio.wav was not created. Please check the ffmpeg output for errors.\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(e)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"FFmpeg Error: {e}\")\n",
        "    print(f\"FFmpeg Stderr: {e.stderr.decode()}\")\n",
        "    print(\"Please make sure input.mp4 exists and is a valid video file. You may need to install additional codecs or packages for ffmpeg.\")\n",
        "\n",
        "\n",
        "# 2. (Preprocessing, if necessary)\n",
        "\n",
        "# 3. Speech-to-Text (using Vosk)\n",
        "model = vosk.Model(model_dir) # Changed to load the model from the directory.\n",
        "rec = vosk.KaldiRecognizer(model, 16000)\n",
        "try:\n",
        "    with open(\"audio.wav\", \"rb\") as wf:\n",
        "        while True:\n",
        "            data = wf.read(4000)\n",
        "            if len(data) == 0:\n",
        "                break\n",
        "            if rec.AcceptWaveform(data):\n",
        "                print(rec.Result())\n",
        "        print(rec.FinalResult())\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Please make sure 'audio.wav' was created in the step above.  Check for ffmpeg errors above\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0orLNRrdd0kh",
        "outputId": "17c93a58-4b81-4505-e5da-8fed0aee00c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vosk in /usr/local/lib/python3.11/dist-packages (0.3.45)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from vosk) (1.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vosk) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vosk) (4.67.1)\n",
            "Requirement already satisfied: srt in /usr/local/lib/python3.11/dist-packages (from vosk) (3.5.3)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from vosk) (14.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->vosk) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (2025.1.31)\n",
            "Model 'vosk-model-en-us-0.22' already exists.\n",
            "Error: input.mp4 not found in the current directory.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install ipywidgets\n",
        "from ipywidgets import FileUpload\n",
        "from IPython.display import display\n",
        "import os\n",
        "\n",
        "def handle_upload(change):\n",
        "    uploaded_file = list(uploader.value.values())[0]\n",
        "    content = uploaded_file['content']\n",
        "    file_name = uploaded_file['name']\n",
        "\n",
        "    with open(file_name, 'wb') as f:\n",
        "        f.write(content)\n",
        "    print(f'Archivo \"{file_name}\" cargado exitosamente.')\n",
        "\n",
        "    #Opcional: Devuelve el nombre del archivo para usarlo posteriormente\n",
        "    return file_name\n",
        "\n",
        "uploader = FileUpload(accept='.mp4,.wav', multiple=False)\n",
        "uploader.observe(handle_upload, names='value')\n",
        "display(uploader)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "rgffuvXaeHjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install vosk\n",
        "!pip install python-docx\n",
        "!pip install langdetect\n",
        "from ipywidgets import FileUpload\n",
        "from IPython.display import display\n",
        "import os\n",
        "import subprocess\n",
        "import vosk\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "from langdetect import detect\n",
        "\n",
        "\n",
        "# 0. Download the model if it doesn't exist (using english as default model)\n",
        "model_name = \"vosk-model-en-us-0.22\"\n",
        "model_dir = model_name\n",
        "if not os.path.exists(model_dir):\n",
        "    print(f\"Downloading model '{model_name}'...\")\n",
        "    !wget https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip\n",
        "    !unzip vosk-model-en-us-0.22.zip\n",
        "    print(\"Model downloaded and extracted.\")\n",
        "else:\n",
        "    print(f\"Model '{model_name}' already exists.\")\n",
        "\n",
        "def get_vosk_model(language):\n",
        "  \"\"\"Download and returns the vosk model based on the specified language.\n",
        "  If the model does not exist, it is downloaded.\n",
        "  If the language is not supported, uses english as default.\n",
        "  \"\"\"\n",
        "  if language == \"es\":\n",
        "      model_name = \"vosk-model-es-0.42\"\n",
        "  elif language == \"fr\":\n",
        "      model_name = \"vosk-model-fr-0.22\"\n",
        "  elif language == \"de\":\n",
        "      model_name = \"vosk-model-de-0.22\"\n",
        "  elif language == \"pt\":\n",
        "      model_name = \"vosk-model-pt-fb-v0.1.1-20200508\"\n",
        "  elif language == \"it\":\n",
        "      model_name = \"vosk-model-it-0.22\"\n",
        "  elif language == \"ru\":\n",
        "        model_name = \"vosk-model-ru-0.42\"\n",
        "  elif language == 'zh':\n",
        "        model_name = \"vosk-model-cn-0.22\"\n",
        "  else:\n",
        "    model_name = \"vosk-model-en-us-0.22\" # Default to english if no supported language is found\n",
        "\n",
        "  model_dir = model_name\n",
        "  if not os.path.exists(model_dir):\n",
        "      print(f\"Downloading model '{model_name}'...\")\n",
        "      try:\n",
        "          !wget https://alphacephei.com/vosk/models/{model_name}.zip\n",
        "          !unzip {model_name}.zip\n",
        "      except:\n",
        "          print(f'Error downloading model: {model_name}, using english model instead')\n",
        "          model_name = \"vosk-model-en-us-0.22\"\n",
        "          model_dir = model_name\n",
        "          if not os.path.exists(model_dir):\n",
        "              print(f\"Downloading model '{model_name}'...\")\n",
        "              !wget https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip\n",
        "              !unzip vosk-model-en-us-0.22.zip\n",
        "              print(\"Model downloaded and extracted.\")\n",
        "  else:\n",
        "      print(f\"Model '{model_name}' already exists.\")\n",
        "  return vosk.Model(model_dir)\n",
        "\n",
        "def create_word_document(text, filename):\n",
        "  \"\"\"Creates a .docx document with the given text and triggers download.\"\"\"\n",
        "  document = Document()\n",
        "  document.add_paragraph(text)\n",
        "  document.save(filename)\n",
        "\n",
        "  # Trigger download\n",
        "  from IPython.display import FileLink\n",
        "  display(FileLink(filename))\n",
        "\n",
        "\n",
        "def transcribe_audio(audio_file, language):\n",
        "    \"\"\"Transcribes an audio file to text using Vosk, identifying the language dynamically.\"\"\"\n",
        "\n",
        "    #1. Extract audio (using ffmpeg)\n",
        "    try:\n",
        "        # Check if input.mp4 or .wav exists\n",
        "      if not os.path.exists(audio_file):\n",
        "            raise FileNotFoundError(f\"Error: {audio_file} not found in the current directory.\")\n",
        "\n",
        "      if audio_file.lower().endswith('.mp4'):\n",
        "         subprocess.run(['ffmpeg', '-i', audio_file, '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', 'audio.wav'], check=True, capture_output=True)\n",
        "         audio_for_transcription = 'audio.wav'\n",
        "      else:\n",
        "          audio_for_transcription = audio_file\n",
        "\n",
        "\n",
        "      # Check if audio.wav exists after ffmpeg\n",
        "      if audio_for_transcription == 'audio.wav' and not os.path.exists('audio.wav'):\n",
        "            raise FileNotFoundError(\"Error: audio.wav was not created. Please check the ffmpeg output for errors.\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "       print(e)\n",
        "       return None\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"FFmpeg Error: {e}\")\n",
        "        print(f\"FFmpeg Stderr: {e.stderr.decode()}\")\n",
        "        print(\"Please make sure input.mp4 exists and is a valid video file. You may need to install additional codecs or packages for ffmpeg.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    # 2. Speech-to-Text (using Vosk)\n",
        "    model = get_vosk_model(language)\n",
        "\n",
        "    rec = vosk.KaldiRecognizer(model, 16000)\n",
        "    try:\n",
        "        with open(audio_for_transcription, \"rb\") as wf:\n",
        "            text_output = \"\"\n",
        "            while True:\n",
        "                data = wf.read(4000)\n",
        "                if len(data) == 0:\n",
        "                    break\n",
        "                if rec.AcceptWaveform(data):\n",
        "                  result = rec.Result()\n",
        "                  text_output += json.loads(result)['text'] + \" \"\n",
        "\n",
        "            result = rec.FinalResult()\n",
        "            text_output += json.loads(result)['text']\n",
        "\n",
        "        if audio_for_transcription == 'audio.wav' and os.path.exists('audio.wav'):\n",
        "          os.remove('audio.wav')\n",
        "        return text_output\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Please make sure 'audio.wav' was created in the step above.  Check for ffmpeg errors above\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def handle_upload(change):\n",
        "    uploaded_file = list(uploader.value.values())[0]\n",
        "    content = uploaded_file['content']\n",
        "    file_name = uploaded_file['name']\n",
        "\n",
        "    with open(file_name, 'wb') as f:\n",
        "        f.write(content)\n",
        "    print(f'Archivo \"{file_name}\" cargado exitosamente.')\n",
        "\n",
        "    try:\n",
        "        language = detect(open(file_name, 'rb').read(1000).decode('utf-8', 'ignore'))\n",
        "        print(f'Detected language: {language}')\n",
        "        text = transcribe_audio(file_name, language)\n",
        "\n",
        "        if text:\n",
        "          doc_filename = os.path.splitext(file_name)[0] + \".docx\"\n",
        "          create_word_document(text, doc_filename)\n",
        "          print(f'Transcription saved to {doc_filename}')\n",
        "        else:\n",
        "          print('Transcription failed')\n",
        "        os.remove(file_name) # remove the temp audio file\n",
        "    except Exception as e:\n",
        "        print('Error during transcription', e)\n",
        "        os.remove(file_name)\n",
        "\n",
        "\n",
        "uploader = FileUpload(accept='.mp4,.wav', multiple=False)\n",
        "uploader.observe(handle_upload, names='value')\n",
        "display(uploader)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "CorP02Q3kPCy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "d4d522f3153b47d39d721d852f8b8d84",
            "0df3b3bc3959406ab806d4999959f5a1",
            "8e4b9b8c70214739ac3068cf6cf1672f"
          ]
        },
        "outputId": "fd58ed46-b7e2-4f68-e60c-2f9a17ede19c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vosk in /usr/local/lib/python3.11/dist-packages (0.3.45)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from vosk) (1.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vosk) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vosk) (4.67.1)\n",
            "Requirement already satisfied: srt in /usr/local/lib/python3.11/dist-packages (from vosk) (3.5.3)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from vosk) (14.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->vosk) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (2025.1.31)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Model 'vosk-model-en-us-0.22' already exists.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='.mp4,.wav', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4d522f3153b47d39d721d852f8b8d84"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "!pip install vosk\n",
        "!pip install python-docx\n",
        "!pip install langdetect\n",
        "!pip install librosa\n",
        "import os\n",
        "import subprocess\n",
        "import vosk\n",
        "import json\n",
        "import librosa\n",
        "from docx import Document\n",
        "from IPython.display import display, FileLink\n",
        "from ipywidgets import FileUpload\n",
        "from langdetect import detect\n",
        "import asyncio\n",
        "\n",
        "# Global dictionary to store loaded models\n",
        "loaded_models = {}\n",
        "\n",
        "# 0. Download the model if it doesn't exist (using english as default model)\n",
        "model_name = \"vosk-model-en-us-0.22\"\n",
        "model_dir = model_name\n",
        "if not os.path.exists(model_dir):\n",
        "    print(f\"Downloading model '{model_name}'...\")\n",
        "    !wget https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip\n",
        "    !unzip vosk-model-en-us-0.22.zip\n",
        "    print(\"Model downloaded and extracted.\")\n",
        "else:\n",
        "    print(f\"Model '{model_name}' already exists.\")\n",
        "\n",
        "\n",
        "async def get_vosk_model(language):\n",
        "    \"\"\"Downloads and returns the vosk model based on the specified language.\n",
        "    Uses a global dictionary for caching models.\n",
        "    \"\"\"\n",
        "    global loaded_models\n",
        "    if language in loaded_models:\n",
        "        return loaded_models[language]\n",
        "\n",
        "\n",
        "    if language == \"es\":\n",
        "        model_name = \"vosk-model-es-0.42\"\n",
        "    elif language == \"fr\":\n",
        "        model_name = \"vosk-model-fr-0.22\"\n",
        "    elif language == \"de\":\n",
        "        model_name = \"vosk-model-de-0.22\"\n",
        "    elif language == \"pt\":\n",
        "        model_name = \"vosk-model-pt-fb-v0.1.1-20200508\"\n",
        "    elif language == \"it\":\n",
        "        model_name = \"vosk-model-it-0.22\"\n",
        "    elif language == \"ru\":\n",
        "          model_name = \"vosk-model-ru-0.42\"\n",
        "    elif language == 'zh':\n",
        "          model_name = \"vosk-model-cn-0.22\"\n",
        "    else:\n",
        "      model_name = \"vosk-model-en-us-0.22\" # Default to english if no supported language is found\n",
        "\n",
        "    model_dir = model_name\n",
        "    if not os.path.exists(model_dir):\n",
        "        print(f\"Downloading model '{model_name}'...\")\n",
        "        try:\n",
        "            !wget https://alphacephei.com/vosk/models/{model_name}.zip\n",
        "            !unzip {model_name}.zip\n",
        "        except Exception as e:\n",
        "            print(f'Error downloading model: {model_name}, using english model instead, {e}')\n",
        "            model_name = \"vosk-model-en-us-0.22\"\n",
        "            model_dir = model_name\n",
        "            if not os.path.exists(model_dir):\n",
        "                print(f\"Downloading model '{model_name}'...\")\n",
        "                !wget https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip\n",
        "                !unzip vosk-model-en-us-0.22.zip\n",
        "                print(\"Model downloaded and extracted.\")\n",
        "    else:\n",
        "        print(f\"Model '{model_name}' already exists.\")\n",
        "\n",
        "    model = vosk.Model(model_dir)\n",
        "    loaded_models[language] = model # Cache the loaded model\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_word_document(text, filename):\n",
        "  \"\"\"Creates a .docx document with the given text and triggers download.\"\"\"\n",
        "  document = Document()\n",
        "  document.add_paragraph(text)\n",
        "  document.save(filename)\n",
        "\n",
        "  # Trigger download\n",
        "  display(FileLink(filename))\n",
        "\n",
        "\n",
        "\n",
        "async def transcribe_audio(audio_file, language):\n",
        "    \"\"\"Transcribes an audio file to text using Vosk, identifying the language dynamically.\"\"\"\n",
        "\n",
        "    #1. Extract audio (using ffmpeg)\n",
        "    try:\n",
        "        # Check if input.mp4 or .wav exists\n",
        "      if not os.path.exists(audio_file):\n",
        "            raise FileNotFoundError(f\"Error: {audio_file} not found in the current directory.\")\n",
        "\n",
        "      audio_for_transcription = audio_file #Default file for transcription\n",
        "      if audio_file.lower().endswith('.mp4'):\n",
        "        # Check if the output audio file already exists\n",
        "        if not os.path.exists('audio.wav'):\n",
        "            subprocess.run(['ffmpeg', '-i', audio_file, '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', 'audio.wav'], check=True, capture_output=True)\n",
        "        audio_for_transcription = 'audio.wav'\n",
        "\n",
        "\n",
        "      # Check if audio.wav exists after ffmpeg\n",
        "      if audio_for_transcription == 'audio.wav' and not os.path.exists('audio.wav'):\n",
        "            raise FileNotFoundError(\"Error: audio.wav was not created. Please check the ffmpeg output for errors.\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "       print(e)\n",
        "       return None\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"FFmpeg Error: {e}\")\n",
        "        print(f\"FFmpeg Stderr: {e.stderr.decode()}\")\n",
        "        print(\"Please make sure input.mp4 exists and is a valid video file. You may need to install additional codecs or packages for ffmpeg.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    # 2. Speech-to-Text (using Vosk)\n",
        "    model = await get_vosk_model(language) # Await the model loading\n",
        "\n",
        "    rec = vosk.KaldiRecognizer(model, 16000)\n",
        "    try:\n",
        "        if audio_for_transcription.lower().endswith('.wav'):\n",
        "           # Using librosa for direct .wav file processing to bypass file IO as much as possible\n",
        "           y, sr = librosa.load(audio_for_transcription, sr=16000)\n",
        "           data = (y * 32768).astype(\"int16\").tobytes()\n",
        "\n",
        "           text_output = \"\"\n",
        "           if rec.AcceptWaveform(data):\n",
        "              text_output += json.loads(rec.Result())['text'] + \" \"\n",
        "           text_output += json.loads(rec.FinalResult())['text']\n",
        "        else:\n",
        "           with open(audio_for_transcription, \"rb\") as wf:\n",
        "              text_output = \"\"\n",
        "              while True:\n",
        "                  data = wf.read(4000)\n",
        "                  if len(data) == 0:\n",
        "                      break\n",
        "                  if rec.AcceptWaveform(data):\n",
        "                    result = rec.Result()\n",
        "                    text_output += json.loads(result)['text'] + \" \"\n",
        "\n",
        "              result = rec.FinalResult()\n",
        "              text_output += json.loads(result)['text']\n",
        "\n",
        "\n",
        "        if audio_for_transcription == 'audio.wav' and os.path.exists('audio.wav'):\n",
        "          os.remove('audio.wav')\n",
        "        return text_output\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Please make sure 'audio.wav' was created in the step above.  Check for ffmpeg errors above\")\n",
        "        return None\n",
        "\n",
        "\n",
        "async def handle_upload(change):\n",
        "    uploaded_file = list(uploader.value.values())[0]\n",
        "    content = uploaded_file['content']\n",
        "    file_name = uploaded_file['name']\n",
        "\n",
        "    with open(file_name, 'wb') as f:\n",
        "        f.write(content)\n",
        "    print(f'Archivo \"{file_name}\" cargado exitosamente.')\n",
        "\n",
        "    try:\n",
        "        language = detect(open(file_name, 'rb').read(1000).decode('utf-8', 'ignore'))\n",
        "        print(f'Detected language: {language}')\n",
        "        text = await transcribe_audio(file_name, language)\n",
        "\n",
        "        if text:\n",
        "          doc_filename = os.path.splitext(file_name)[0] + \".docx\"\n",
        "          create_word_document(text, doc_filename)\n",
        "          print(f'Transcription saved to {doc_filename}')\n",
        "        else:\n",
        "          print('Transcription failed')\n",
        "        os.remove(file_name) # remove the temp audio file\n",
        "    except Exception as e:\n",
        "        print('Error during transcription', e)\n",
        "        os.remove(file_name)\n",
        "\n",
        "\n",
        "uploader = FileUpload(accept='.mp4,.wav', multiple=False)\n",
        "uploader.observe(lambda change: asyncio.run(handle_upload(change)), names='value')\n",
        "display(uploader)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "PFCiNA-cMO6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import vosk\n",
        "import json\n",
        "import librosa\n",
        "import ffmpeg\n",
        "import numpy as np\n",
        "from docx import Document\n",
        "from langdetect import detect\n",
        "from google.colab import files\n",
        "\n",
        "# Diccionario global para modelos cargados\n",
        "loaded_models = {}\n",
        "\n",
        "# Función para obtener el modelo de Vosk sin descargarlo repetidamente\n",
        "def get_vosk_model(language):\n",
        "    global loaded_models\n",
        "    if language in loaded_models:\n",
        "        return loaded_models[language]\n",
        "\n",
        "    models = {\n",
        "        \"es\": \"vosk-model-es-0.42\",\n",
        "        \"fr\": \"vosk-model-fr-0.22\",\n",
        "        \"de\": \"vosk-model-de-0.22\",\n",
        "        \"pt\": \"vosk-model-pt-fb-v0.1.1-20200508\",\n",
        "        \"it\": \"vosk-model-it-0.22\",\n",
        "        \"ru\": \"vosk-model-ru-0.42\",\n",
        "        \"zh\": \"vosk-model-cn-0.22\",\n",
        "        \"default\": \"vosk-model-en-us-0.22\"\n",
        "    }\n",
        "\n",
        "    model_name = models.get(language, models[\"default\"])\n",
        "    model_path = f\"/content/{model_name}\"\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Descargando modelo {model_name}...\")\n",
        "        os.system(f\"wget -q https://alphacephei.com/vosk/models/{model_name}.zip && unzip -q {model_name}.zip -d /content\")\n",
        "\n",
        "    loaded_models[language] = vosk.Model(model_path)\n",
        "    return loaded_models[language]\n",
        "\n",
        "# Función optimizada de transcripción\n",
        "def transcribe_audio(audio_file, language=\"es\"):\n",
        "    model = get_vosk_model(language)\n",
        "    rec = vosk.KaldiRecognizer(model, 16000)\n",
        "\n",
        "    # Cargar el audio con librosa\n",
        "    y, sr = librosa.load(audio_file, sr=16000)\n",
        "    audio_data = (y * 32768).astype(np.int16).tobytes()\n",
        "\n",
        "    # Procesar audio en fragmentos grandes\n",
        "    chunk_size = 8000  # 0.5s por fragmento\n",
        "    text_output = \"\"\n",
        "    for i in range(0, len(audio_data), chunk_size):\n",
        "        if rec.AcceptWaveform(audio_data[i:i+chunk_size]):\n",
        "            text_output += json.loads(rec.Result())[\"text\"] + \" \"\n",
        "    text_output += json.loads(rec.FinalResult())[\"text\"]\n",
        "\n",
        "    return text_output.strip()\n",
        "\n",
        "# Función para guardar la transcripción en un archivo Word\n",
        "def create_word_document(text, filename):\n",
        "    document = Document()\n",
        "    document.add_paragraph(text)\n",
        "    document.save(filename)\n",
        "    files.download(filename)\n",
        "\n",
        "# Función principal para manejar la subida y transcripción de archivos\n",
        "def handle_upload():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"Procesando {filename}...\")\n",
        "        try:\n",
        "            text = transcribe_audio(filename)\n",
        "            if text:\n",
        "                doc_filename = filename.rsplit('.', 1)[0] + \".docx\"\n",
        "                create_word_document(text, doc_filename)\n",
        "                print(f\"Transcripción guardada en {doc_filename}\")\n",
        "            else:\n",
        "                print(\"Error: No se pudo obtener la transcripción.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error procesando {filename}: {e}\")\n",
        "\n",
        "# Llamar a la función para subir archivos\n",
        "display(\"Sube un archivo .mp4 o .wav para transcribir:\")\n",
        "handle_upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "DFa2vZKYP1fY",
        "outputId": "3bb4b8dd-3030-409f-b259-e8952c579373"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ffmpeg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6839d31e6523>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mffmpeg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdocx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ffmpeg'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "source": [
        "!pip install ffmpeg-python\n",
        "import os\n",
        "import vosk\n",
        "import json\n",
        "import librosa\n",
        "import ffmpeg as ff # Changed import\n",
        "import numpy as np\n",
        "from docx import Document\n",
        "from langdetect import detect\n",
        "from google.colab import files\n",
        "\n",
        "# Diccionario global para modelos cargados\n",
        "loaded_models = {}\n",
        "\n",
        "# Función para obtener el modelo de Vosk sin descargarlo repetidamente\n",
        "def get_vosk_model(language):\n",
        "    global loaded_models\n",
        "    if language in loaded_models:\n",
        "        return loaded_models[language]\n",
        "\n",
        "    models = {\n",
        "        \"es\": \"vosk-model-es-0.42\",\n",
        "        \"fr\": \"vosk-model-fr-0.22\",\n",
        "        \"de\": \"vosk-model-de-0.22\",\n",
        "        \"pt\": \"vosk-model-pt-fb-v0.1.1-20200508\",\n",
        "        \"it\": \"vosk-model-it-0.22\",\n",
        "        \"ru\": \"vosk-model-ru-0.42\",\n",
        "        \"zh\": \"vosk-model-cn-0.22\",\n",
        "        \"default\": \"vosk-model-en-us-0.22\"\n",
        "    }\n",
        "\n",
        "    model_name = models.get(language, models[\"default\"])\n",
        "    model_path = f\"/content/{model_name}\"\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Descargando modelo {model_name}...\")\n",
        "        os.system(f\"wget -q https://alphacephei.com/vosk/models/{model_name}.zip && unzip -q {model_name}.zip -d /content\")\n",
        "\n",
        "    loaded_models[language] = vosk.Model(model_path)\n",
        "    return loaded_models[language]\n",
        "\n",
        "# Función optimizada de transcripción\n",
        "def transcribe_audio(audio_file, language=\"es\"):\n",
        "    model = get_vosk_model(language)\n",
        "    rec = vosk.KaldiRecognizer(model, 16000)\n",
        "\n",
        "    # Cargar el audio con librosa\n",
        "    y, sr = librosa.load(audio_file, sr=16000)\n",
        "    audio_data = (y * 32768).astype(np.int16).tobytes()\n",
        "\n",
        "    # Procesar audio en fragmentos grandes\n",
        "    chunk_size = 8000  # 0.5s por fragmento\n",
        "    text_output = \"\"\n",
        "    for i in range(0, len(audio_data), chunk_size):\n",
        "        if rec.AcceptWaveform(audio_data[i:i+chunk_size]):\n",
        "            text_output += json.loads(rec.Result())[\"text\"] + \" \"\n",
        "    text_output += json.loads(rec.FinalResult())[\"text\"]\n",
        "\n",
        "    return text_output.strip()\n",
        "\n",
        "# Función para guardar la transcripción en un archivo Word\n",
        "def create_word_document(text, filename):\n",
        "    document = Document()\n",
        "    document.add_paragraph(text)\n",
        "    document.save(filename)\n",
        "    files.download(filename)\n",
        "\n",
        "# Función principal para manejar la subida y transcripción de archivos\n",
        "def handle_upload():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"Procesando {filename}...\")\n",
        "        try:\n",
        "            text = transcribe_audio(filename)\n",
        "            if text:\n",
        "                doc_filename = filename.rsplit('.', 1)[0] + \".docx\"\n",
        "                create_word_document(text, doc_filename)\n",
        "                print(f\"Transcripción guardada en {doc_filename}\")\n",
        "            else:\n",
        "                print(\"Error: No se pudo obtener la transcripción.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error procesando {filename}: {e}\")\n",
        "\n",
        "# Llamar a la función para subir archivos\n",
        "display(\"Sube un archivo .mp4 o .wav para transcribir:\")\n",
        "handle_upload()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "jCHsGs_xQU7G",
        "outputId": "42b83cd1-d52e-4d9f-a10a-cd3bf67b9700"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Sube un archivo .mp4 o .wav para transcribir:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-891ddb42-717b-4328-a232-899fd4521887\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-891ddb42-717b-4328-a232-899fd4521887\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Vídeo sin título ‐ Hecho con Clipchamp (2).srt to Vídeo sin título ‐ Hecho con Clipchamp (2).srt\n",
            "Procesando Vídeo sin título ‐ Hecho con Clipchamp (2).srt...\n",
            "Descargando modelo vosk-model-es-0.42...\n",
            "Error procesando Vídeo sin título ‐ Hecho con Clipchamp (2).srt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-faa2bd317042>:48: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  y, sr = librosa.load(audio_file, sr=16000)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import vosk\n",
        "import json\n",
        "import ffmpeg\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from docx import Document\n",
        "from langdetect import detect\n",
        "from google.colab import files\n",
        "\n",
        "# Diccionario global para modelos cargados\n",
        "loaded_models = {}\n",
        "\n",
        "# Función para obtener el modelo de Vosk sin descargarlo repetidamente\n",
        "def get_vosk_model(language):\n",
        "    global loaded_models\n",
        "    if language in loaded_models:\n",
        "        return loaded_models[language]\n",
        "\n",
        "    models = {\n",
        "        \"es\": \"vosk-model-es-0.42\",\n",
        "        \"fr\": \"vosk-model-fr-0.22\",\n",
        "        \"de\": \"vosk-model-de-0.22\",\n",
        "        \"pt\": \"vosk-model-pt-fb-v0.1.1-20200508\",\n",
        "        \"it\": \"vosk-model-it-0.22\",\n",
        "        \"ru\": \"vosk-model-ru-0.42\",\n",
        "        \"zh\": \"vosk-model-cn-0.22\",\n",
        "        \"default\": \"vosk-model-en-us-0.22\"\n",
        "    }\n",
        "\n",
        "    model_name = models.get(language, models[\"default\"])\n",
        "    model_path = f\"/content/{model_name}\"\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Descargando modelo {model_name}...\")\n",
        "        os.system(f\"wget -q https://alphacephei.com/vosk/models/{model_name}.zip && unzip -q {model_name}.zip -d /content\")\n",
        "\n",
        "    loaded_models[language] = vosk.Model(model_path)\n",
        "    return loaded_models[language]\n",
        "\n",
        "# Función para convertir audio a WAV si es necesario\n",
        "def convert_to_wav(audio_file):\n",
        "    wav_file = audio_file.rsplit('.', 1)[0] + \".wav\"\n",
        "    if not audio_file.lower().endswith(\".wav\"):\n",
        "        print(f\"Convirtiendo {audio_file} a formato WAV...\")\n",
        "        ffmpeg.input(audio_file).output(wav_file, format='wav', acodec='pcm_s16le', ac=1, ar='16000').run(overwrite_output=True)\n",
        "    else:\n",
        "        wav_file = audio_file\n",
        "    return wav_file\n",
        "\n",
        "# Función optimizada de transcripción\n",
        "def transcribe_audio(audio_file, language=\"es\"):\n",
        "    model = get_vosk_model(language)\n",
        "    rec = vosk.KaldiRecognizer(model, 16000)\n",
        "\n",
        "    audio_file = convert_to_wav(audio_file)\n",
        "\n",
        "    with sf.SoundFile(audio_file) as sf_file:\n",
        "        audio_data = sf_file.read(dtype='int16')\n",
        "        audio_data = np.array(audio_data, dtype=np.int16).tobytes()\n",
        "\n",
        "    # Procesar audio en fragmentos grandes\n",
        "    chunk_size = 8000  # 0.5s por fragmento\n",
        "    text_output = \"\"\n",
        "    for i in range(0, len(audio_data), chunk_size):\n",
        "        if rec.AcceptWaveform(audio_data[i:i+chunk_size]):\n",
        "            text_output += json.loads(rec.Result())[\"text\"] + \" \"\n",
        "    text_output += json.loads(rec.FinalResult())[\"text\"]\n",
        "\n",
        "    return text_output.strip()\n",
        "\n",
        "# Función para guardar la transcripción en un archivo Word\n",
        "def create_word_document(text, filename):\n",
        "    document = Document()\n",
        "    document.add_paragraph(text)\n",
        "    document.save(filename)\n",
        "    files.download(filename)\n",
        "\n",
        "# Función principal para manejar la subida y transcripción de archivos\n",
        "def handle_upload():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"Procesando {filename}...\")\n",
        "        try:\n",
        "            text = transcribe_audio(filename)\n",
        "            if text:\n",
        "                doc_filename = filename.rsplit('.', 1)[0] + \".docx\"\n",
        "                create_word_document(text, doc_filename)\n",
        "                print(f\"Transcripción guardada en {doc_filename}\")\n",
        "            else:\n",
        "                print(\"Error: No se pudo obtener la transcripción.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error procesando {filename}: {e}\")\n",
        "\n",
        "# Llamar a la función para subir archivos\n",
        "display(\"Sube un archivo .mp4 o .wav para transcribir:\")\n",
        "handle_upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "DR-XD5DnSlFS",
        "outputId": "32749a59-ce29-4cfb-9f3d-1ccd2f86bff4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Sube un archivo .mp4 o .wav para transcribir:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1e0aea4c-bba9-41d0-9e17-f552e1c1ef25\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1e0aea4c-bba9-41d0-9e17-f552e1c1ef25\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Vídeo sin título ‐ Hecho con Clipchamp (3).mp4 to Vídeo sin título ‐ Hecho con Clipchamp (3).mp4\n",
            "Procesando Vídeo sin título ‐ Hecho con Clipchamp (3).mp4...\n",
            "Convirtiendo Vídeo sin título ‐ Hecho con Clipchamp (3).mp4 a formato WAV...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3405ac85-d41a-43f0-808f-c53e83c4549a\", \"Vi\\u0301deo sin ti\\u0301tulo \\u2010 Hecho con Clipchamp (3).docx\", 36673)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcripción guardada en Vídeo sin título ‐ Hecho con Clipchamp (3).docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import vosk\n",
        "import json\n",
        "import ffmpeg\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from docx import Document\n",
        "from langdetect import detect\n",
        "from google.colab import files\n",
        "\n",
        "# Diccionario global para modelos cargados\n",
        "loaded_models = {}\n",
        "\n",
        "# Función para obtener el modelo de Vosk sin descargarlo repetidamente\n",
        "def get_vosk_model(language):\n",
        "    global loaded_models\n",
        "    if language in loaded_models:\n",
        "        return loaded_models[language]\n",
        "\n",
        "    models = {\n",
        "        \"es\": \"vosk-model-es-0.42\",\n",
        "        \"fr\": \"vosk-model-fr-0.22\",\n",
        "        \"de\": \"vosk-model-de-0.22\",\n",
        "        \"pt\": \"vosk-model-pt-fb-v0.1.1-20200508\",\n",
        "        \"it\": \"vosk-model-it-0.22\",\n",
        "        \"ru\": \"vosk-model-ru-0.42\",\n",
        "        \"zh\": \"vosk-model-cn-0.22\",\n",
        "        \"default\": \"vosk-model-en-us-0.22\"\n",
        "    }\n",
        "\n",
        "    model_name = models.get(language, models[\"default\"])\n",
        "    model_path = f\"/content/{model_name}\"\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"Descargando modelo {model_name}...\")\n",
        "        os.system(f\"wget -q https://alphacephei.com/vosk/models/{model_name}.zip && unzip -q {model_name}.zip -d /content\")\n",
        "\n",
        "    loaded_models[language] = vosk.Model(model_path)\n",
        "    return loaded_models[language]\n",
        "\n",
        "# Función para convertir audio a WAV si es necesario\n",
        "def convert_to_wav(audio_file):\n",
        "    wav_file = audio_file.rsplit('.', 1)[0] + \".wav\"\n",
        "    if not audio_file.lower().endswith(\".wav\"):\n",
        "        print(f\"Convirtiendo {audio_file} a formato WAV...\")\n",
        "        ffmpeg.input(audio_file).output(wav_file, format='wav', acodec='pcm_s16le', ac=1, ar='16000').run(overwrite_output=True)\n",
        "    else:\n",
        "        wav_file = audio_file\n",
        "    return wav_file\n",
        "\n",
        "# Función optimizada de transcripción\n",
        "def transcribe_audio(audio_file, language=\"es\"):\n",
        "    model = get_vosk_model(language)\n",
        "    rec = vosk.KaldiRecognizer(model, 16000)\n",
        "\n",
        "    audio_file = convert_to_wav(audio_file)\n",
        "\n",
        "    with sf.SoundFile(audio_file) as sf_file:\n",
        "        audio_data = sf_file.read(dtype='int16')\n",
        "        audio_data = np.array(audio_data, dtype=np.int16).tobytes()\n",
        "\n",
        "    # Procesar audio en fragmentos grandes\n",
        "    chunk_size = 8000  # 0.5s por fragmento\n",
        "    text_output = \"\"\n",
        "    for i in range(0, len(audio_data), chunk_size):\n",
        "        if rec.AcceptWaveform(audio_data[i:i+chunk_size]):\n",
        "            text_output += json.loads(rec.Result())[\"text\"] + \" \"\n",
        "    text_output += json.loads(rec.FinalResult())[\"text\"]\n",
        "\n",
        "    return text_output.strip()\n",
        "\n",
        "# Función para guardar la transcripción en un archivo Word\n",
        "def create_word_document(text, filename):\n",
        "    document = Document()\n",
        "    document.add_paragraph(text)\n",
        "    document.save(filename)\n",
        "    files.download(filename)\n",
        "\n",
        "# Función principal para manejar la subida y transcripción de archivos\n",
        "def handle_upload():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        print(f\"Procesando {filename}...\")\n",
        "        try:\n",
        "            text = transcribe_audio(filename)\n",
        "            if text:\n",
        "                doc_filename = filename.rsplit('.', 1)[0] + \".docx\"\n",
        "                create_word_document(text, doc_filename)\n",
        "                print(f\"Transcripción guardada en {doc_filename}\")\n",
        "            else:\n",
        "                print(\"Error: No se pudo obtener la transcripción.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error procesando {filename}: {e}\")\n",
        "\n",
        "# Llamar a la función para subir archivos\n",
        "display(\"Sube un archivo .mp4 o .wav para transcribir:\")\n",
        "handle_upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "444Lg11QUgHD",
        "outputId": "9efe7064-ae01-47d6-8f29-2997948eca8f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Sube un archivo .mp4 o .wav para transcribir:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f1736ef3-db07-460a-b3c8-63bee1e7e55c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f1736ef3-db07-460a-b3c8-63bee1e7e55c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Vídeo sin título ‐ Hecho con Clipchamp (3).mp4 to Vídeo sin título ‐ Hecho con Clipchamp (3) (1).mp4\n",
            "Procesando Vídeo sin título ‐ Hecho con Clipchamp (3) (1).mp4...\n",
            "Convirtiendo Vídeo sin título ‐ Hecho con Clipchamp (3) (1).mp4 a formato WAV...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e25c595d-4e00-4b0a-bca5-a82100a6dd3b\", \"Vi\\u0301deo sin ti\\u0301tulo \\u2010 Hecho con Clipchamp (3) (1).docx\", 36673)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcripción guardada en Vídeo sin título ‐ Hecho con Clipchamp (3) (1).docx\n"
          ]
        }
      ]
    }
  ]
}